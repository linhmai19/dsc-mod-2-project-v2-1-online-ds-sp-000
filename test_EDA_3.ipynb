{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Linh Mai\n",
    "* Student pace: self paced \n",
    "* Scheduled project review date/time: June 3rd, 2020\n",
    "* Instructor name: Jeff Herman\n",
    "* Blog post URL: https://linhmai19.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_kc_house_data.csv')\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the scatter plots for of each feature against the target 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "\n",
    "for xcol, ax in zip(df.columns[1:4], axes):\n",
    "    df.plot(kind='scatter', x=xcol, y='price', ax=ax, alpha=0.3, color='peru', sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "\n",
    "for xcol, ax in zip(df.columns[4:7], axes):\n",
    "    df.plot(kind='scatter', x=xcol, y='price', ax=ax, alpha=0.3, color='peru', sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "\n",
    "for xcol, ax in zip(df.columns[7:10], axes):\n",
    "    df.plot(kind='scatter', x=xcol, y='price', ax=ax, alpha=0.3, color='peru', sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "\n",
    "for xcol, ax in zip(df.columns[10:13], axes):\n",
    "    df.plot(kind='scatter', x=xcol, y='price', ax=ax, alpha=0.3, color='peru', sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "\n",
    "for xcol, ax in zip(df.columns[13:16], axes):\n",
    "    df.plot(kind='scatter', x=xcol, y='price', ax=ax, alpha=0.3, color='peru', sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "\n",
    "for xcol, ax in zip(df.columns[16:19], axes):\n",
    "    df.plot(kind='scatter', x=xcol, y='price', ax=ax, alpha=0.3, color='peru', sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(column, df[column].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the histograms and the number of unique values above, the categorical data are basements, bedrooms, bathrooms, floors, waterfront, view, condition, grade, yr_built, yr_sold, latitude, longitude, and zipcode. \n",
    "\n",
    "However, bathrooms, bedrooms, floors, grade variables have numeric data and hierarchical orders. For example, 3 bedrooms ranks higher than 2 bedrooms which ranks higher than 1 bedroom. Therefore, these features can be used in models without having to perform label encoding or creating dummy variables.\n",
    "\n",
    "For the 'zipcode', it does not have a hierachical order. Therefore, one hot encoding is done in order to include them in the model. However, there are 70 unique zipcodes which are a lot to create addition columns. These 70 zipcodes are placed in 10 different bins and then performing one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the pentiles of zipcode\n",
    "df['zipcode'].quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9, 1])\n",
    "\n",
    "#creating bins based on the quartiles\n",
    "bins = [98000, 98008, 98028, 98038, 98053, 98065, 98103, 98115, 98125, 98155, 98200]\n",
    "bins_cut = pd.cut(df['zipcode'], bins)\n",
    "bins_cut = bins_cut.cat.as_ordered()\n",
    "bins_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check the created bins for 'zipcode'\n",
    "graph = sns.countplot(data=df, x=bins_cut, order=bins_cut.value_counts().index)\n",
    "graph.set_xticklabels(graph.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy variables for 'zipcode' and deal with dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, replace the original 'zipcode' column with the created 'bins_cut'\n",
    "df['zipcode']=bins_cut\n",
    "\n",
    "# Create dummy variables, dropping one variable to avoid dummy variable trap\n",
    "zipcode_dummies = pd.get_dummies(df['zipcode'], prefix = 'zip', drop_first=True)\n",
    "\n",
    "# Then, drop the original 'zipcode' column\n",
    "df = df.drop('zipcode', axis=1).copy()\n",
    "\n",
    "# Add the zipcode dummy variables into the existing dataframe\n",
    "df = pd.concat([df, zipcode_dummies], axis=1).copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to change the name of zipcode_dummies columns to avoid errors when doing modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'zip_(98008, 98028]':'zip_98008_98028', 'zip_(98028, 98038]':'zip_98028_98038',\n",
    "                        'zip_(98038, 98053]':'zip_98038_98053', 'zip_(98053, 98065]':'zip_98053_98065', \n",
    "                        'zip_(98065, 98103]':'zip_98065_98103', 'zip_(98103, 98115]':'zip_98103_98115', \n",
    "                        'zip_(98115, 98125]':'zip_98115_98125', 'zip_(98125, 98155]':'zip_98125_98155',\n",
    "                        'zip_(98155, 98200]':'zip_98155_98200'}).copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latitude and longitude are also categorical variables with no hierachical order. However, since the zipcode is already \"treated\", we can used this data to predict the house price for a simpler model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop both 'lat' and 'long' columns\n",
    "df = df.drop(['lat', 'long'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy variables for basement, condition, view, waterfront, yr_built, yr_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for yr_built\n",
    "bins_yr_built = pd.cut(df['yr_built'], [1899, 1920, 1940, 1960, 1980, 2000, 2020])\n",
    "bins_yr_built = bins_yr_built.cat.as_unordered()\n",
    "\n",
    "# Create dummy variables, dropping one variable to avoid dummy variable trap\n",
    "yr_built_dummies = pd.get_dummies(bins_yr_built, prefix='yr_built', drop_first=True)\n",
    "yr_sold_dummies = pd.get_dummies(df['yr_sold'], prefix='yr_sold', drop_first=True)\n",
    "view_dummies = pd.get_dummies(df['view'], prefix='view', drop_first=True)\n",
    "wt_front_dummies = pd.get_dummies(df['waterfront'], prefix='wt_front', drop_first=True)\n",
    "con_dummies = pd.get_dummies(df['condition'], prefix='con', drop_first=True)\n",
    "base_dummies = pd.get_dummies(df['basement'], prefix='base', drop_first=True)\n",
    "\n",
    "# Drop the original columns and add dummy variables into the existing dataframe\n",
    "df = df.drop(['yr_built','yr_sold','view','waterfront','condition','basement'], axis=1).copy()\n",
    "df = pd.concat([df, yr_built_dummies, yr_sold_dummies, view_dummies, wt_front_dummies, \n",
    "                con_dummies, base_dummies], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Multicollinearity of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr() > 0.75)\n",
    "plt.title('Correlation > 0.75')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap plot above, 'sqft_living' is correlated with 'sqft_above' and 'sqft_lot' is correlated with 'sqft_lot15'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 'sqft_living', 'sqft_above', 'sqft_lot' and 'sqft_lot15' against the target 'price' to determine which features are highly correlated with the target higher than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation values between: \n",
    "\n",
    "Price and 'sqft_living' = 0.53\n",
    "\n",
    "Price and 'sqft_above' = 0.4\n",
    "\n",
    "Price and 'sqft_lot' = -0.076\n",
    "\n",
    "Price and 'sqft_lot15' = -0.085\n",
    "\n",
    "Based on the correlation values above, we drop the 'sqft_above' and 'sqft_lot15' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sqft_above', 'sqft_lot15'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert all of our numeric columns to the same scale by normalizing our dataset. We normalize the data by converting each numeric value to it's corresponding z-score for the column, which is obtained by subtracting the column's mean and then dividing by the column's standard deviation for every value.\n",
    "\n",
    "'price' is not normalized because this is the feature to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use KDE plots to visualize the distribution of variables \n",
    "for feat in ['sqft_living', 'sqft_lot', 'sqft_living15', 'floors']:\n",
    "    sns.kdeplot(df[feat], bw=0.5)\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['sqft_living', 'sqft_lot', 'sqft_living15', 'floors']:\n",
    "    df[feat] = df[feat].map(lambda x: np.log(x))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the KDE plots again for the results after normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['sqft_living', 'sqft_lot', 'sqft_living15', 'floors']:\n",
    "    sns.kdeplot(df[feat], bw=0.5)\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the independent variables follow a normal distribution. The next step is equalize their magnitudes by scaling them using min-max scaling method. Only continuous variables are selected for this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for min-max scaling\n",
    "def scale(column):\n",
    "    maximum = column.max()\n",
    "    minimum = column.min()\n",
    "    y = (column - minimum)/(maximum-minimum)\n",
    "    return y\n",
    "\n",
    "scale_vars = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'view', 'condition', 'grade', 'sqft_living15']\n",
    "\n",
    "for feat in scale_vars:\n",
    "    df[feat] = scale(df[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see whether the features have been scaled\n",
    "df[scale_vars].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
